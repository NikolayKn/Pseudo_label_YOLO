{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import gdown\n",
    "import shutil\n",
    "import yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É —Å –≥—É–≥–ª –¥–∏—Å–∫–∞\n",
    "def load_pseudo_labels(\n",
    "        dataset_name, #VOC\n",
    "        ann_name, # –ù–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "        ann_postfix, # –ü–æ—Å—Ç—Ñ–∏–∫—Å —Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "        url # –£—Ä–ª, —á—Ç–æ–±—ã —Å–∫–∞—á–∞—Ç—å (google disk)\n",
    "        ):\n",
    "    \n",
    "    save_dir = f'../data/pseudo_labels/{dataset_name}'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "    filename = f'{save_dir}/{ann_name}.zip'\n",
    "    gdown.download(url, filename, quiet = True, fuzzy = True)\n",
    "    !unzip -d {save_dir} {filename} \n",
    "\n",
    "    # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –ø–∞–ø–∫—É —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º\n",
    "    for sample in (['train', 'test', 'val']):\n",
    "        lbs_source = f'{save_dir}/{ann_name}/{sample}'\n",
    "        if os.path.exists(lbs_source) is False:\n",
    "            print(f'{lbs_source} does not exisist')\n",
    "            continue\n",
    "        lbs_dest = f'../datasets/{dataset_name}/labels/{sample}_{ann_postfix}'\n",
    "        shutil.copytree(lbs_source, lbs_dest)\n",
    "\n",
    "# –ü–æ–¥–≥—Ä—É–∑–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "def prepare_labels(dataset_name, # –ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "                   train_postfix=None, # –†–∞–∑–º–µ—Ç–∫–∞, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è [orig, GD]\n",
    "                   val_postfix=None, # –†–∞–∑–º–µ—Ç–∫–∞, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è [orig, GD]\n",
    "                   test_postfix=None # –†–∞–∑–º–µ—Ç–∫–∞, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è [orig, GD]\n",
    "                   ):\n",
    "    # –ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É –Ω–∞ —Ä–∞–∑–º–µ—Ç–∫—É –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω—É—é\n",
    "    for sample, postfix in zip(['train', 'val', 'test'], [train_postfix, val_postfix, test_postfix]):\n",
    "        if postfix is None:\n",
    "            postfix = 'orig'\n",
    "\n",
    "        lbs_dest = f'../datasets/{dataset_name}/labels/{sample}'\n",
    "        lbs_source = f'../datasets/{dataset_name}/labels/{sample}_{postfix}'\n",
    "        !rm -rf {lbs_dest}\n",
    "        shutil.copytree(lbs_source, lbs_dest)\n",
    "\n",
    "# –ß—Ç–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞\n",
    "def read_yaml_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        try:\n",
    "            data = yaml.safe_load(file)\n",
    "            return data\n",
    "        except yaml.YAMLError as e:\n",
    "            print(\"Error reading YAML file:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É —Å –≥—É–≥–ª –¥–∏—Å–∫–∞\n",
    "# load_pseudo_labels(\n",
    "#         dataset_name='VOC', #VOC\n",
    "#         ann_name='annotations_nms_0.7_p_0.4', # –ù–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "#         ann_postfix='GD', # –ü–æ—Å—Ç—Ñ–∏–∫—Å —Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "#         url='https://drive.google.com/file/d/1K9-6IppbpJTnLivh80Or4Oj5tZUgd3ej/view?usp=sharing' # –£—Ä–ª, —á—Ç–æ–±—ã —Å–∫–∞—á–∞—Ç—å (google disk)\n",
    "#         )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args.yaml\t\t\t PR_curve.png\t   val_batch0_labels.jpg\n",
      "confusion_matrix_normalized.png  R_curve.png\t   val_batch0_pred.jpg\n",
      "confusion_matrix.png\t\t results.csv\t   val_batch1_labels.jpg\n",
      "F1_curve.png\t\t\t results.png\t   val_batch1_pred.jpg\n",
      "labels_correlogram.jpg\t\t train_batch0.jpg  val_batch2_labels.jpg\n",
      "labels.jpg\t\t\t train_batch1.jpg  val_batch2_pred.jpg\n",
      "P_curve.png\t\t\t train_batch2.jpg  weights\n"
     ]
    }
   ],
   "source": [
    "!ls runs/detect/orig_yolov8n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nikolay/Documents/Projects/Diploma/My repos/Pseudo_label_YOLO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolay/Documents/Projects/Diploma/My repos/Pseudo_label_YOLO/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.35 üöÄ Python-3.10.6 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5938MiB)\n",
      "Model summary (fused): 168 layers, 3009548 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/nikolay/Documents/Projects/Diploma/My repos/Pseudo_label_YOLO/datasets/VOC/labels/test.cache... 4952 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4952/4952 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 496/496 [00:22<00:00, 22.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4952      12032      0.731      0.425      0.542      0.367\n",
      "             aeroplane       4952        285       0.72      0.515      0.596      0.416\n",
      "               bicycle       4952        337      0.658      0.608       0.65      0.425\n",
      "                  bird       4952        459      0.723      0.414      0.507      0.322\n",
      "                  boat       4952        263       0.81     0.0164      0.327      0.185\n",
      "                bottle       4952        469      0.345     0.0405      0.112      0.078\n",
      "                   bus       4952        213          1     0.0119      0.121     0.0887\n",
      "                   car       4952       1201      0.656      0.734      0.755      0.553\n",
      "                   cat       4952        358      0.567      0.768      0.717      0.464\n",
      "                 chair       4952        756      0.535      0.437      0.477      0.306\n",
      "                   cow       4952        244      0.733      0.316      0.466      0.356\n",
      "           diningtable       4952        206      0.934     0.0689      0.521      0.358\n",
      "                   dog       4952        489      0.872      0.319      0.595      0.405\n",
      "                 horse       4952        348      0.744      0.736      0.772      0.543\n",
      "             motorbike       4952        325      0.751       0.72      0.755      0.482\n",
      "                person       4952       4528      0.733      0.705      0.783      0.536\n",
      "           pottedplant       4952        480      0.926      0.026      0.206      0.116\n",
      "                 sheep       4952        242      0.823        0.5      0.659       0.46\n",
      "                  sofa       4952        239       0.44      0.632      0.533      0.414\n",
      "                 train       4952        282       0.75       0.67      0.693      0.426\n",
      "             tvmonitor       4952        308      0.903      0.272        0.6      0.401\n",
      "Speed: 0.2ms preprocess, 2.2ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "weight_path = 'notebooks/runs/detect/orig_yolov8n_train/weights/best.pt'\n",
    "model =YOLO(weight_path)\n",
    "validation_results = model.val(data='datasets/VOC/VOC_test.yaml', imgsz=640, batch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('runs/detect/val2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_results.save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configs  datasets   README.md\t      runs    yolov8n.pt\n",
      "data\t notebooks  requirements.txt  source\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'torch._C.Generator' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49msave(validation_results, \u001b[39m'\u001b[39;49m\u001b[39mmodel_state_dict.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/Projects/Diploma/My repos/Pseudo_label_YOLO/.venv/lib/python3.10/site-packages/ultralytics/utils/patches.py:84\u001b[0m, in \u001b[0;36mtorch_save\u001b[0;34m(use_dill, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m):  \u001b[39m# 3 retries\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m         \u001b[39mreturn\u001b[39;00m _torch_save(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     85\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# unable to save, possibly waiting for device to flush or antivirus scan\u001b[39;00m\n\u001b[1;32m     86\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Projects/Diploma/My repos/Pseudo_label_YOLO/.venv/lib/python3.10/site-packages/torch/serialization.py:629\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    628\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 629\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    630\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Projects/Diploma/My repos/Pseudo_label_YOLO/.venv/lib/python3.10/site-packages/torch/serialization.py:841\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    839\u001b[0m pickler \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mPickler(data_buf, protocol\u001b[39m=\u001b[39mpickle_protocol)\n\u001b[1;32m    840\u001b[0m pickler\u001b[39m.\u001b[39mpersistent_id \u001b[39m=\u001b[39m persistent_id\n\u001b[0;32m--> 841\u001b[0m pickler\u001b[39m.\u001b[39;49mdump(obj)\n\u001b[1;32m    842\u001b[0m data_value \u001b[39m=\u001b[39m data_buf\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    843\u001b[0m zip_file\u001b[39m.\u001b[39mwrite_record(\u001b[39m'\u001b[39m\u001b[39mdata.pkl\u001b[39m\u001b[39m'\u001b[39m, data_value, \u001b[39mlen\u001b[39m(data_value))\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'torch._C.Generator' object"
     ]
    }
   ],
   "source": [
    "torch.save(validation_results, 'model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file\n",
    "pickle.dump(validation_results.box, file = open(f'{str(validation_results.save_dir)}/results.pickle', \"wb\"))\n",
    "# Reload the file\n",
    "# company1_reloaded = pickle.load(open(\"company1.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded = pickle.load(open(f'{str(validation_results.save_dir)}/results.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.59646,     0.64999,     0.50722,     0.32681,     0.11159,     0.12132,     0.75523,     0.71697,     0.47709,     0.46577,      0.5214,     0.59464,     0.77223,     0.75525,     0.78346,     0.20647,     0.65879,     0.53316,     0.69266,     0.60043])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded.ap50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.027735,    0.012984,   0.0093837,   0.0024506,   0.0018597,   0.0058105,    0.035251,    0.024297,     0.01992,    0.037053,     0.00579,    0.033996,    0.047395,   0.0098933,    0.055887,   0.0019691,    0.025987,    0.096861,   0.0062307,    0.016254])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics.box.map    # map50-95\n",
    "# metrics.box.map50  # map50\n",
    "# metrics.box.map75  # map75\n",
    "# metrics.box.maps \n",
    "validation_results.box.all_ap[:,-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
