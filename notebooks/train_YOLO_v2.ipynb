{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import gdown\n",
    "import shutil\n",
    "import yaml\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É —Å –≥—É–≥–ª –¥–∏—Å–∫–∞\n",
    "def load_pseudo_labels(\n",
    "        dataset_name, #VOC\n",
    "        ann_name, # –ù–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "        ann_postfix, # –ü–æ—Å—Ç—Ñ–∏–∫—Å —Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "        url # –£—Ä–ª, —á—Ç–æ–±—ã —Å–∫–∞—á–∞—Ç—å (google disk)\n",
    "        ):\n",
    "    \n",
    "    save_dir = f'../data/pseudo_labels/{dataset_name}'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "    filename = f'{save_dir}/{ann_name}.zip'\n",
    "    gdown.download(url, filename, quiet = True, fuzzy = True)\n",
    "    !unzip -d {save_dir} {filename} \n",
    "\n",
    "    # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –ø–∞–ø–∫—É —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º\n",
    "    for sample in (['train', 'test', 'val']):\n",
    "        lbs_source = f'{save_dir}/{ann_name}/{sample}'\n",
    "        if os.path.exists(lbs_source) is False:\n",
    "            print(f'{lbs_source} does not exisist')\n",
    "            continue\n",
    "        lbs_dest = f'../datasets/{dataset_name}/labels/{sample}_{ann_postfix}'\n",
    "        shutil.copytree(lbs_source, lbs_dest)\n",
    "\n",
    "# –ü–æ–¥–≥—Ä—É–∑–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "def prepare_labels(dataset_name, # –ù–∞–∑–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "                   train_postfix=None, # –†–∞–∑–º–µ—Ç–∫–∞, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è [orig, GD]\n",
    "                   val_postfix=None, # –†–∞–∑–º–µ—Ç–∫–∞, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è [orig, GD]\n",
    "                   test_postfix=None # –†–∞–∑–º–µ—Ç–∫–∞, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è [orig, GD]\n",
    "                   ):\n",
    "    # –ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É –Ω–∞ —Ä–∞–∑–º–µ—Ç–∫—É –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω—É—é\n",
    "    for sample, postfix in zip(['train', 'val', 'test'], [train_postfix, val_postfix, test_postfix]):\n",
    "        if postfix is None:\n",
    "            postfix = 'orig'\n",
    "\n",
    "        lbs_dest = f'../datasets/{dataset_name}/labels/{sample}'\n",
    "        lbs_source = f'../datasets/{dataset_name}/labels/{sample}_{postfix}'\n",
    "        !rm -rf {lbs_dest}\n",
    "        shutil.copytree(lbs_source, lbs_dest)\n",
    "\n",
    "# –ß—Ç–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞\n",
    "def read_yaml_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        try:\n",
    "            data = yaml.safe_load(file)\n",
    "            return data\n",
    "        except yaml.YAMLError as e:\n",
    "            print(\"Error reading YAML file:\", e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É —Å –≥—É–≥–ª –¥–∏—Å–∫–∞\n",
    "# load_pseudo_labels(\n",
    "#         dataset_name='VOC', #VOC\n",
    "#         ann_name='annotations_nms_0.7_p_0.4', # –ù–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "#         ann_postfix='GD', # –ü–æ—Å—Ç—Ñ–∏–∫—Å —Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "#         url='https://drive.google.com/file/d/1K9-6IppbpJTnLivh80Or4Oj5tZUgd3ej/view?usp=sharing' # –£—Ä–ª, —á—Ç–æ–±—ã —Å–∫–∞—á–∞—Ç—å (google disk)\n",
    "#         )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.41 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.35 üöÄ Python-3.10.6 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5938MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=../datasets/VOC/VOC.yaml, epochs=3, time=None, patience=100, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=2, project=None, name=train13, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train13\n",
      "Overriding model.yaml nc=80 with nc=20\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    755212  ultralytics.nn.modules.head.Detect           [20, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3014748 parameters, 3014732 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU) 5.80G total, 0.33G reserved, 0.05G allocated, 5.41G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "     3014748       8.215         0.415         49.27         36.56        (1, 3, 640, 640)                    list\n",
      "     3014748       16.43         0.417         12.46         33.55        (2, 3, 640, 640)                    list\n",
      "     3014748       32.86         0.679         12.99         36.82        (4, 3, 640, 640)                    list\n",
      "     3014748       65.72         1.181         17.85         35.35        (8, 3, 640, 640)                    list\n",
      "     3014748       131.4         2.059         30.95         56.33       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 26 for CUDA:0 3.58G/5.80G (62%) ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/nikolay/Documents/Projects/Diploma/My repos/Pseudo_label_YOLO/datasets/VOC/labels/train... 2501 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2501/2501 [00:00<00:00, 2925.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/nikolay/Documents/Projects/Diploma/My repos/Pseudo_label_YOLO/datasets/VOC/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/nikolay/Documents/Projects/Diploma/My repos/Pseudo_label_YOLO/datasets/VOC/labels/val... 2510 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2510/2510 [00:01<00:00, 2504.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/nikolay/Documents/Projects/Diploma/My repos/Pseudo_label_YOLO/datasets/VOC/labels/val.cache\n",
      "Plotting labels to runs/detect/train13/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000417, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00040625000000000004), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train13\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      3.63G     0.9771       3.23      1.238         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97/97 [00:19<00:00,  5.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49/49 [00:09<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2510       6307      0.676      0.434      0.555      0.375\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      3.64G      1.037      1.949      1.292         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97/97 [00:17<00:00,  5.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49/49 [00:08<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2510       6307      0.659      0.627      0.674      0.462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3      3.59G     0.9841      1.714      1.255         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97/97 [00:17<00:00,  5.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49/49 [00:08<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2510       6307      0.714      0.656      0.723      0.503\n",
      "\n",
      "3 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from runs/detect/train13/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/train13/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/train13/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.35 üöÄ Python-3.10.6 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5938MiB)\n",
      "Model summary (fused): 168 layers, 3009548 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49/49 [00:10<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2510       6307      0.716      0.656      0.723      0.503\n",
      "             aeroplane       2510        155      0.683      0.826      0.805      0.541\n",
      "               bicycle       2510        177      0.709      0.734       0.78      0.532\n",
      "                  bird       2510        243      0.734      0.556      0.669      0.446\n",
      "                  boat       2510        150      0.693       0.52        0.6      0.377\n",
      "                bottle       2510        252      0.764      0.553      0.673      0.452\n",
      "                   bus       2510        114      0.636      0.613      0.641      0.541\n",
      "                   car       2510        625      0.774      0.832      0.869      0.666\n",
      "                   cat       2510        190       0.84      0.726      0.831      0.615\n",
      "                 chair       2510        398      0.595      0.557      0.597      0.414\n",
      "                   cow       2510        123      0.829      0.528       0.74      0.557\n",
      "           diningtable       2510        112       0.67      0.453      0.613      0.361\n",
      "                   dog       2510        257      0.663      0.743      0.753      0.546\n",
      "                 horse       2510        180      0.665      0.872      0.823      0.588\n",
      "             motorbike       2510        172      0.817      0.674       0.79      0.544\n",
      "                person       2510       2332      0.826      0.755      0.849      0.573\n",
      "           pottedplant       2510        266      0.584       0.47      0.489       0.25\n",
      "                 sheep       2510        127      0.839      0.409       0.67      0.476\n",
      "                  sofa       2510        124       0.59      0.645      0.605      0.423\n",
      "                 train       2510        152       0.79      0.868      0.889      0.611\n",
      "             tvmonitor       2510        158      0.618      0.778      0.776      0.548\n",
      "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train13\u001b[0m\n",
      "Ultralytics YOLOv8.1.35 üöÄ Python-3.10.6 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5938MiB)\n",
      "Model summary (fused): 168 layers, 3009548 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/nikolay/Documents/Projects/Diploma/My repos/Pseudo_label_YOLO/datasets/VOC/labels/test.cache... 4952 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4952/4952 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 237/310 [00:35<00:41,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è NMS time limit 2.800s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 271/310 [01:15<03:00,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è NMS time limit 2.800s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 289/310 [02:00<00:43,  2.08s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "experiments = read_yaml_file('../configs/VOC_original.yaml')\n",
    "for exp in experiments:\n",
    "    prepare_labels(**exp['data_config'])\n",
    "    model = YOLO(exp['model'])\n",
    "    results = model.train(**exp['train_config'])\n",
    "\n",
    "    directory_old_train = str(results.save_dir)\n",
    "    dir_new_train = f'{exp[\"saving_directory\"]}_{exp[\"model\"].split(\".\")[0]}_train'\n",
    "    os.rename(directory_old_train, dir_new_train)\n",
    "\n",
    "    #test\n",
    "    weight_path = f'{dir_new_train}/weights/best.pt'\n",
    "    model =YOLO(weight_path)\n",
    "    validation_results = model.val(**exp['test_config'])\n",
    "    pickle.dump(validation_results.box, file = open(f'{str(validation_results.save_dir)}/results.pickle', \"wb\"))\n",
    "\n",
    "    directory_old_test = str(validation_results.save_dir)\n",
    "    dir_new_test = f'{exp[\"saving_directory\"]}_{exp[\"model\"].split(\".\")[0]}_test'\n",
    "    os.rename(directory_old_test, dir_new_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.651476823857488"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_results.box.map50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4456083040486212"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics.box.map    # map50-95\n",
    "# metrics.box.map50  # map50\n",
    "# metrics.box.map75  # map75\n",
    "# metrics.box.maps \n",
    "validation_results.box.map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
